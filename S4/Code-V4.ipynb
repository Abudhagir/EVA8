{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:16:49.788801Z","iopub.execute_input":"2023-01-27T14:16:49.789740Z","iopub.status.idle":"2023-01-27T14:16:52.453847Z","shell.execute_reply.started":"2023-01-27T14:16:49.789639Z","shell.execute_reply":"2023-01-27T14:16:52.452741Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Train Phase transformations\ntrain_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n                                       # Note the difference between (0.1307) and (0.1307,)\n                                       ])\n\n# Test Phase transformations\ntest_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,))\n                                       ])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:17:00.861043Z","iopub.execute_input":"2023-01-27T14:17:00.861552Z","iopub.status.idle":"2023-01-27T14:17:00.868239Z","shell.execute_reply.started":"2023-01-27T14:17:00.861518Z","shell.execute_reply":"2023-01-27T14:17:00.867134Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\ntest = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:17:05.403835Z","iopub.execute_input":"2023-01-27T14:17:05.404542Z","iopub.status.idle":"2023-01-27T14:17:07.260192Z","shell.execute_reply.started":"2023-01-27T14:17:05.404505Z","shell.execute_reply":"2023-01-27T14:17:07.259125Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12ff82e5bc7c4af3abfa58668d0472ca"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9852484cc54e30b9e4f32b5dc7b46c"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41eca1e129eb4d9c92ae05d90ba847a8"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c808d4f523104a2780d40471cbb88349"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 1\n\n# CUDA?\ncuda = torch.cuda.is_available()\nprint(\"CUDA Available?\", cuda)\n\n# For reproducibility\ntorch.manual_seed(SEED)\n\nif cuda:\n    torch.cuda.manual_seed(SEED)\n\n# dataloader arguments - something you'll fetch these from cmdprmt\ndataloader_args = dict(shuffle=True, batch_size=128, num_workers=2, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n\n# train dataloader\ntrain_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n\n# test dataloader\ntest_loader = torch.utils.data.DataLoader(test, **dataloader_args)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:17:10.005979Z","iopub.execute_input":"2023-01-27T14:17:10.006828Z","iopub.status.idle":"2023-01-27T14:17:10.134391Z","shell.execute_reply.started":"2023-01-27T14:17:10.006795Z","shell.execute_reply":"2023-01-27T14:17:10.133399Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"CUDA Available? True\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn.functional as F\ndropout_value = 0.001\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # Input Block\n        self.convblock1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(8),\n            nn.Dropout(dropout_value)\n        ) # output_size = 8\n\n        # CONVOLUTION BLOCK 1\n        self.convblock2 = nn.Sequential(\n            nn.Conv2d(in_channels=8, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 10\n\n        # TRANSITION BLOCK 1\n        self.convblock3 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=12, kernel_size=(1, 1), padding=0, bias=False),\n        ) # output_size = 12\n        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n\n        # CONVOLUTION BLOCK 2\n        self.convblock4 = nn.Sequential(\n            nn.Conv2d(in_channels=12, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(14),\n            nn.Dropout(dropout_value)\n        ) # output_size = 14\n        self.convblock5 = nn.Sequential(\n            nn.Conv2d(in_channels=14, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 16\n        self.convblock6 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 16\n        self.convblock7 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=18, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(18),\n            nn.Dropout(dropout_value)\n        ) # output_size = 18\n        \n          \n        # OUTPUT BLOCK\n        self.gap = nn.Sequential(\n            nn.AvgPool2d(kernel_size=6)\n        ) # output_size = 1\n\n        self.convblock8 = nn.Sequential(\n            nn.Conv2d(in_channels=18, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n            # nn.BatchNorm2d(10),\n            # nn.ReLU(),\n            # nn.Dropout(dropout_value)\n        ) \n\n\n        self.dropout = nn.Dropout(dropout_value)\n\n    def forward(self, x):\n        x = self.convblock1(x)\n        x = self.convblock2(x)\n        x = self.convblock3(x)\n        x = self.pool1(x)\n        x = self.convblock4(x)\n        x = self.convblock5(x)\n        x = self.convblock6(x)\n        x = self.convblock7(x)\n        #x = self.convblock8(x)\n        #x = self.convblock9(x)\n        x = self.gap(x)        \n        x = self.convblock8(x)\n\n        x = x.view(-1, 10)\n        return F.log_softmax(x, dim=-1)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:17:13.231850Z","iopub.execute_input":"2023-01-27T14:17:13.232392Z","iopub.status.idle":"2023-01-27T14:17:13.251803Z","shell.execute_reply.started":"2023-01-27T14:17:13.232359Z","shell.execute_reply":"2023-01-27T14:17:13.250967Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nprint(device)\nmodel = Net().to(device)\nsummary(model, input_size=(1, 28, 28))","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:17:42.975433Z","iopub.execute_input":"2023-01-27T14:17:42.975787Z","iopub.status.idle":"2023-01-27T14:18:04.394289Z","shell.execute_reply.started":"2023-01-27T14:17:42.975757Z","shell.execute_reply":"2023-01-27T14:18:04.392112Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mcuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 8, 26, 26]              72\n              ReLU-2            [-1, 8, 26, 26]               0\n       BatchNorm2d-3            [-1, 8, 26, 26]              16\n           Dropout-4            [-1, 8, 26, 26]               0\n            Conv2d-5           [-1, 10, 24, 24]             720\n              ReLU-6           [-1, 10, 24, 24]               0\n       BatchNorm2d-7           [-1, 10, 24, 24]              20\n           Dropout-8           [-1, 10, 24, 24]               0\n            Conv2d-9           [-1, 12, 24, 24]             120\n        MaxPool2d-10           [-1, 12, 12, 12]               0\n           Conv2d-11           [-1, 14, 10, 10]           1,512\n             ReLU-12           [-1, 14, 10, 10]               0\n      BatchNorm2d-13           [-1, 14, 10, 10]              28\n          Dropout-14           [-1, 14, 10, 10]               0\n           Conv2d-15             [-1, 16, 8, 8]           2,016\n             ReLU-16             [-1, 16, 8, 8]               0\n      BatchNorm2d-17             [-1, 16, 8, 8]              32\n          Dropout-18             [-1, 16, 8, 8]               0\n           Conv2d-19             [-1, 16, 6, 6]           2,304\n             ReLU-20             [-1, 16, 6, 6]               0\n      BatchNorm2d-21             [-1, 16, 6, 6]              32\n          Dropout-22             [-1, 16, 6, 6]               0\n           Conv2d-23             [-1, 18, 6, 6]           2,592\n             ReLU-24             [-1, 18, 6, 6]               0\n      BatchNorm2d-25             [-1, 18, 6, 6]              36\n          Dropout-26             [-1, 18, 6, 6]               0\n        AvgPool2d-27             [-1, 18, 1, 1]               0\n           Conv2d-28             [-1, 10, 1, 1]             180\n================================================================\nTotal params: 9,680\nTrainable params: 9,680\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.52\nParams size (MB): 0.04\nEstimated Total Size (MB): 0.56\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses = []\ntest_losses = []\ntrain_acc = []\ntest_acc = []\n\ndef train(model, device, train_loader, optimizer, epoch):\n  model.train()\n  pbar = tqdm(train_loader)\n  correct = 0\n  processed = 0\n  for batch_idx, (data, target) in enumerate(pbar):\n    # get samples\n    data, target = data.to(device), target.to(device)\n\n    # Init\n    optimizer.zero_grad()\n    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n\n    # Predict\n    y_pred = model(data)\n\n    # Calculate loss\n    loss = F.nll_loss(y_pred, target)\n    train_losses.append(loss)\n\n    # Backpropagation\n    loss.backward()\n    optimizer.step()\n\n    # Update pbar-tqdm\n    \n    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n    correct += pred.eq(target.view_as(pred)).sum().item()\n    processed += len(data)\n\n    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n    train_acc.append(100*correct/processed)\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    test_losses.append(test_loss)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    \n    test_acc.append(100. * correct / len(test_loader.dataset))","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:18:41.240700Z","iopub.execute_input":"2023-01-27T14:18:41.241110Z","iopub.status.idle":"2023-01-27T14:18:41.255523Z","shell.execute_reply.started":"2023-01-27T14:18:41.241074Z","shell.execute_reply":"2023-01-27T14:18:41.254538Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses = []\ntest_losses = []\ntrain_acc = []\ntest_acc = []\n\ndef train(model, device, train_loader, optimizer, epoch):\n  model.train()\n  pbar = tqdm(train_loader)\n  correct = 0\n  processed = 0\n  for batch_idx, (data, target) in enumerate(pbar):\n    # get samples\n    data, target = data.to(device), target.to(device)\n\n    # Init\n    optimizer.zero_grad()\n    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n\n    # Predict\n    y_pred = model(data)\n\n    # Calculate loss\n    loss = F.nll_loss(y_pred, target)\n    train_losses.append(loss)\n\n    # Backpropagation\n    loss.backward()\n    optimizer.step()\n\n    # Update pbar-tqdm\n    \n    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n    correct += pred.eq(target.view_as(pred)).sum().item()\n    processed += len(data)\n\n    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n    train_acc.append(100*correct/processed)\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    test_losses.append(test_loss)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    \n    test_acc.append(100. * correct / len(test_loader.dataset))","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:18:51.870686Z","iopub.execute_input":"2023-01-27T14:18:51.871165Z","iopub.status.idle":"2023-01-27T14:18:51.883428Z","shell.execute_reply.started":"2023-01-27T14:18:51.871129Z","shell.execute_reply":"2023-01-27T14:18:51.882233Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\nmodel =  Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nscheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n\n\nEPOCHS = 15\nfor epoch in range(EPOCHS):\n    print(\"EPOCH:\", epoch)\n    train(model, device, train_loader, optimizer, epoch)\n    # scheduler.step()\n    test(model, device, test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T14:19:04.544779Z","iopub.execute_input":"2023-01-27T14:19:04.545229Z","iopub.status.idle":"2023-01-27T14:24:24.561403Z","shell.execute_reply.started":"2023-01-27T14:19:04.545176Z","shell.execute_reply":"2023-01-27T14:24:24.560260Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"EPOCH: 0\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.059393275529146194 Batch_id=468 Accuracy=90.89: 100%|██████████| 469/469 [00:18<00:00, 24.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0743, Accuracy: 9817/10000 (98.17%)\n\nEPOCH: 1\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.02746191807091236 Batch_id=468 Accuracy=97.94: 100%|██████████| 469/469 [00:19<00:00, 23.94it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0487, Accuracy: 9857/10000 (98.57%)\n\nEPOCH: 2\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.016949601471424103 Batch_id=468 Accuracy=98.48: 100%|██████████| 469/469 [00:19<00:00, 23.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0379, Accuracy: 9892/10000 (98.92%)\n\nEPOCH: 3\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.023355966433882713 Batch_id=468 Accuracy=98.64: 100%|██████████| 469/469 [00:19<00:00, 24.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0308, Accuracy: 9908/10000 (99.08%)\n\nEPOCH: 4\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.015821747481822968 Batch_id=468 Accuracy=98.81: 100%|██████████| 469/469 [00:19<00:00, 24.22it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0254, Accuracy: 9927/10000 (99.27%)\n\nEPOCH: 5\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.030276566743850708 Batch_id=468 Accuracy=98.95: 100%|██████████| 469/469 [00:19<00:00, 24.01it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0268, Accuracy: 9918/10000 (99.18%)\n\nEPOCH: 6\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.05055415257811546 Batch_id=468 Accuracy=98.97: 100%|██████████| 469/469 [00:18<00:00, 24.92it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0251, Accuracy: 9931/10000 (99.31%)\n\nEPOCH: 7\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.029815951362252235 Batch_id=468 Accuracy=99.05: 100%|██████████| 469/469 [00:19<00:00, 24.63it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0223, Accuracy: 9919/10000 (99.19%)\n\nEPOCH: 8\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.039291948080062866 Batch_id=468 Accuracy=99.07: 100%|██████████| 469/469 [00:19<00:00, 24.15it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0305, Accuracy: 9900/10000 (99.00%)\n\nEPOCH: 9\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.02865520864725113 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:18<00:00, 24.81it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0233, Accuracy: 9926/10000 (99.26%)\n\nEPOCH: 10\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.008176637813448906 Batch_id=468 Accuracy=99.19: 100%|██████████| 469/469 [00:19<00:00, 24.68it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0235, Accuracy: 9920/10000 (99.20%)\n\nEPOCH: 11\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.004473887849599123 Batch_id=468 Accuracy=99.20: 100%|██████████| 469/469 [00:19<00:00, 23.91it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0232, Accuracy: 9929/10000 (99.29%)\n\nEPOCH: 12\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.005894538480788469 Batch_id=468 Accuracy=99.20: 100%|██████████| 469/469 [00:19<00:00, 24.50it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0200, Accuracy: 9940/10000 (99.40%)\n\nEPOCH: 13\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.07915382087230682 Batch_id=468 Accuracy=99.30: 100%|██████████| 469/469 [00:19<00:00, 23.93it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0198, Accuracy: 9947/10000 (99.47%)\n\nEPOCH: 14\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.019245238974690437 Batch_id=468 Accuracy=99.31: 100%|██████████| 469/469 [00:19<00:00, 24.00it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0215, Accuracy: 9934/10000 (99.34%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}