{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:53:10.115790Z","iopub.execute_input":"2023-01-20T15:53:10.116183Z","iopub.status.idle":"2023-01-20T15:53:10.526779Z","shell.execute_reply.started":"2023-01-20T15:53:10.116151Z","shell.execute_reply":"2023-01-20T15:53:10.525836Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Train Phase transformations\ntrain_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n                                       # Note the difference between (0.1307) and (0.1307,)\n                                       ])\n\n# Test Phase transformations\ntest_transforms = transforms.Compose([\n                                      #  transforms.Resize((28, 28)),\n                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,))\n                                       ])","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:53:12.160660Z","iopub.execute_input":"2023-01-20T15:53:12.161077Z","iopub.status.idle":"2023-01-20T15:53:12.168807Z","shell.execute_reply.started":"2023-01-20T15:53:12.161036Z","shell.execute_reply":"2023-01-20T15:53:12.167555Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\ntest = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:53:17.528223Z","iopub.execute_input":"2023-01-20T15:53:17.528770Z","iopub.status.idle":"2023-01-20T15:53:19.057839Z","shell.execute_reply.started":"2023-01-20T15:53:17.528718Z","shell.execute_reply":"2023-01-20T15:53:19.056275Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8492defdc94b2c9aca7158c5d996df"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad59a898c586445eb5882ff5eba0c347"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b822d3075f5e436dbac0c029e8adb153"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d47389be4c744899a99e17fa4c4f6ca2"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 1\n\n# CUDA?\ncuda = torch.cuda.is_available()\nprint(\"CUDA Available?\", cuda)\n\n# For reproducibility\ntorch.manual_seed(SEED)\n\nif cuda:\n    torch.cuda.manual_seed(SEED)\n\n# dataloader arguments - something you'll fetch these from cmdprmt\ndataloader_args = dict(shuffle=True, batch_size=128, num_workers=2, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n\n# train dataloader\ntrain_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n\n# test dataloader\ntest_loader = torch.utils.data.DataLoader(test, **dataloader_args)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T15:53:26.776717Z","iopub.execute_input":"2023-01-20T15:53:26.777116Z","iopub.status.idle":"2023-01-20T15:53:26.906148Z","shell.execute_reply.started":"2023-01-20T15:53:26.777084Z","shell.execute_reply":"2023-01-20T15:53:26.905073Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"CUDA Available? True\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn.functional as F\ndropout_value = 0.15\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # Input Block\n        self.convblock1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(8),\n            nn.Dropout(dropout_value)\n        ) # output_size = 26\n\n        # CONVOLUTION BLOCK 1\n        self.convblock2 = nn.Sequential(\n            nn.Conv2d(in_channels=8, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),\n            nn.BatchNorm2d(10),\n            nn.Dropout(dropout_value)\n        ) # output_size = 24\n\n        # TRANSITION BLOCK 1\n        self.convblock3 = nn.Sequential(\n            nn.Conv2d(in_channels=10, out_channels=12, kernel_size=(1, 1), padding=0, bias=False),\n        ) # output_size = 24\n        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n\n        # CONVOLUTION BLOCK 2\n        self.convblock4 = nn.Sequential(\n            nn.Conv2d(in_channels=12, out_channels=14, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(14),\n            nn.Dropout(dropout_value)\n        ) # output_size = 10\n        self.convblock5 = nn.Sequential(\n            nn.Conv2d(in_channels=14, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 8\n        self.convblock6 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 6\n        self.convblock7 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n            nn.ReLU(),            \n            nn.BatchNorm2d(16),\n            nn.Dropout(dropout_value)\n        ) # output_size = 6\n        \n        # OUTPUT BLOCK\n        self.gap = nn.Sequential(\n            nn.AvgPool2d(kernel_size=6)\n        ) # output_size = 1\n\n        self.convblock8 = nn.Sequential(\n            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n            # nn.BatchNorm2d(10),\n            # nn.ReLU(),\n            # nn.Dropout(dropout_value)\n        ) \n\n\n        self.dropout = nn.Dropout(dropout_value)\n\n    def forward(self, x):\n        x = self.convblock1(x)\n        x = self.convblock2(x)\n        x = self.convblock3(x)\n        x = self.pool1(x)\n        x = self.convblock4(x)\n        x = self.convblock5(x)\n        x = self.convblock6(x)\n        x = self.convblock7(x)\n        x = self.gap(x)        \n        x = self.convblock8(x)\n\n        x = x.view(-1, 10)\n        return F.log_softmax(x, dim=-1)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T16:07:14.586333Z","iopub.execute_input":"2023-01-20T16:07:14.586726Z","iopub.status.idle":"2023-01-20T16:07:14.607256Z","shell.execute_reply.started":"2023-01-20T16:07:14.586690Z","shell.execute_reply":"2023-01-20T16:07:14.606100Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#!pip install torchsummary\nfrom torchsummary import summary\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nprint(device)\nmodel = Net().to(device)\nsummary(model, input_size=(1, 28, 28))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T16:07:17.214525Z","iopub.execute_input":"2023-01-20T16:07:17.214908Z","iopub.status.idle":"2023-01-20T16:07:17.234527Z","shell.execute_reply.started":"2023-01-20T16:07:17.214876Z","shell.execute_reply":"2023-01-20T16:07:17.233048Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 8, 26, 26]              72\n              ReLU-2            [-1, 8, 26, 26]               0\n       BatchNorm2d-3            [-1, 8, 26, 26]              16\n           Dropout-4            [-1, 8, 26, 26]               0\n            Conv2d-5           [-1, 10, 24, 24]             720\n              ReLU-6           [-1, 10, 24, 24]               0\n       BatchNorm2d-7           [-1, 10, 24, 24]              20\n           Dropout-8           [-1, 10, 24, 24]               0\n            Conv2d-9           [-1, 12, 24, 24]             120\n        MaxPool2d-10           [-1, 12, 12, 12]               0\n           Conv2d-11           [-1, 14, 10, 10]           1,512\n             ReLU-12           [-1, 14, 10, 10]               0\n      BatchNorm2d-13           [-1, 14, 10, 10]              28\n          Dropout-14           [-1, 14, 10, 10]               0\n           Conv2d-15             [-1, 16, 8, 8]           2,016\n             ReLU-16             [-1, 16, 8, 8]               0\n      BatchNorm2d-17             [-1, 16, 8, 8]              32\n          Dropout-18             [-1, 16, 8, 8]               0\n           Conv2d-19             [-1, 16, 6, 6]           2,304\n             ReLU-20             [-1, 16, 6, 6]               0\n      BatchNorm2d-21             [-1, 16, 6, 6]              32\n          Dropout-22             [-1, 16, 6, 6]               0\n           Conv2d-23             [-1, 16, 6, 6]           2,304\n             ReLU-24             [-1, 16, 6, 6]               0\n      BatchNorm2d-25             [-1, 16, 6, 6]              32\n          Dropout-26             [-1, 16, 6, 6]               0\n        AvgPool2d-27             [-1, 16, 1, 1]               0\n           Conv2d-28             [-1, 10, 1, 1]             160\n================================================================\nTotal params: 9,368\nTrainable params: 9,368\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.52\nParams size (MB): 0.04\nEstimated Total Size (MB): 0.55\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses = []\ntest_losses = []\ntrain_acc = []\ntest_acc = []\n\ndef train(model, device, train_loader, optimizer, epoch):\n  model.train()\n  pbar = tqdm(train_loader)\n  correct = 0\n  processed = 0\n  for batch_idx, (data, target) in enumerate(pbar):\n    # get samples\n    data, target = data.to(device), target.to(device)\n\n    # Init\n    optimizer.zero_grad()\n    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n\n    # Predict\n    y_pred = model(data)\n\n    # Calculate loss\n    loss = F.nll_loss(y_pred, target)\n    train_losses.append(loss)\n\n    # Backpropagation\n    loss.backward()\n    optimizer.step()\n\n    # Update pbar-tqdm\n    \n    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n    correct += pred.eq(target.view_as(pred)).sum().item()\n    processed += len(data)\n\n    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n    train_acc.append(100*correct/processed)\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    test_losses.append(test_loss)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    \n    test_acc.append(100. * correct / len(test_loader.dataset))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T16:07:23.495778Z","iopub.execute_input":"2023-01-20T16:07:23.496609Z","iopub.status.idle":"2023-01-20T16:07:23.753453Z","shell.execute_reply.started":"2023-01-20T16:07:23.496573Z","shell.execute_reply":"2023-01-20T16:07:23.752383Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\nmodel =  Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nscheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n\n\nEPOCHS = 15\nfor epoch in range(EPOCHS):\n    print(\"EPOCH:\", epoch)\n    train(model, device, train_loader, optimizer, epoch)\n    # scheduler.step()\n    test(model, device, test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T16:07:28.651888Z","iopub.execute_input":"2023-01-20T16:07:28.652617Z","iopub.status.idle":"2023-01-20T16:13:18.056938Z","shell.execute_reply.started":"2023-01-20T16:07:28.652580Z","shell.execute_reply":"2023-01-20T16:13:18.055734Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"EPOCH: 0\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.07927357405424118 Batch_id=468 Accuracy=85.37: 100%|██████████| 469/469 [00:20<00:00, 23.04it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0733, Accuracy: 9802/10000 (98.02%)\n\nEPOCH: 1\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.16061489284038544 Batch_id=468 Accuracy=96.85: 100%|██████████| 469/469 [00:20<00:00, 23.13it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0519, Accuracy: 9848/10000 (98.48%)\n\nEPOCH: 2\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.05744098126888275 Batch_id=468 Accuracy=97.53: 100%|██████████| 469/469 [00:21<00:00, 22.06it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0481, Accuracy: 9858/10000 (98.58%)\n\nEPOCH: 3\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.09556970745325089 Batch_id=468 Accuracy=97.81: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0474, Accuracy: 9856/10000 (98.56%)\n\nEPOCH: 4\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.044546693563461304 Batch_id=468 Accuracy=98.03: 100%|██████████| 469/469 [00:20<00:00, 23.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0390, Accuracy: 9881/10000 (98.81%)\n\nEPOCH: 5\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.11980553716421127 Batch_id=468 Accuracy=98.25: 100%|██████████| 469/469 [00:20<00:00, 22.53it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0311, Accuracy: 9906/10000 (99.06%)\n\nEPOCH: 6\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.021568967029452324 Batch_id=468 Accuracy=98.30: 100%|██████████| 469/469 [00:21<00:00, 22.26it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0403, Accuracy: 9873/10000 (98.73%)\n\nEPOCH: 7\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.09312119334936142 Batch_id=468 Accuracy=98.41: 100%|██████████| 469/469 [00:20<00:00, 22.45it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0309, Accuracy: 9901/10000 (99.01%)\n\nEPOCH: 8\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.04074610024690628 Batch_id=468 Accuracy=98.36: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0361, Accuracy: 9889/10000 (98.89%)\n\nEPOCH: 9\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.06242290511727333 Batch_id=468 Accuracy=98.47: 100%|██████████| 469/469 [00:20<00:00, 22.52it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0288, Accuracy: 9903/10000 (99.03%)\n\nEPOCH: 10\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.08458718657493591 Batch_id=468 Accuracy=98.51: 100%|██████████| 469/469 [00:21<00:00, 22.06it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0337, Accuracy: 9893/10000 (98.93%)\n\nEPOCH: 11\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.004018397536128759 Batch_id=468 Accuracy=98.61: 100%|██████████| 469/469 [00:21<00:00, 21.92it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0278, Accuracy: 9915/10000 (99.15%)\n\nEPOCH: 12\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.02908491902053356 Batch_id=468 Accuracy=98.61: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0257, Accuracy: 9918/10000 (99.18%)\n\nEPOCH: 13\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.015536289662122726 Batch_id=468 Accuracy=98.72: 100%|██████████| 469/469 [00:21<00:00, 21.51it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0289, Accuracy: 9907/10000 (99.07%)\n\nEPOCH: 14\n","output_type":"stream"},{"name":"stderr","text":"Loss=0.06978695839643478 Batch_id=468 Accuracy=98.57: 100%|██████████| 469/469 [00:21<00:00, 21.43it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0299, Accuracy: 9911/10000 (99.11%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-01-20T16:21:00.767840Z","iopub.execute_input":"2023-01-20T16:21:00.768214Z","iopub.status.idle":"2023-01-20T16:21:00.774891Z","shell.execute_reply.started":"2023-01-20T16:21:00.768183Z","shell.execute_reply":"2023-01-20T16:21:00.773454Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#%matplotlib inline\n#import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(2,2,figsize=(15,10))\naxs[0, 0].plot(train_losses)\naxs[0, 0].set_title(\"Training Loss\")\naxs[1, 0].plot(train_acc[4000:])\naxs[1, 0].set_title(\"Training Accuracy\")\naxs[0, 1].plot(test_losses)\naxs[0, 1].set_title(\"Test Loss\")\naxs[1, 1].plot(test_acc)\naxs[1, 1].set_title(\"Test Accuracy\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T16:21:04.448943Z","iopub.execute_input":"2023-01-20T16:21:04.449719Z","iopub.status.idle":"2023-01-20T16:21:05.084817Z","shell.execute_reply.started":"2023-01-20T16:21:04.449680Z","shell.execute_reply":"2023-01-20T16:21:05.082451Z"},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3696570777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \"\"\"\n\u001b[1;32m   1634\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[0;31m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             len(x.shape) < 1):\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."],"ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x720 with 4 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA3IAAAJDCAYAAABOhiZdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlF0lEQVR4nO3db4il51k/8O/VrFGstYq7gmQ3JvLbWpcqtA6xImilVTZ5sfvCPyRQtBK6oEZEixBRqsRXVVQQonXFUhVsGvtCBlyJoJGAmJIt1dCkRMZYm41CYq15U9oYvX4vzlHHcbdzzu6ZeZ478/nAwnmeczPn4mZ2v/ud5zxnqrsDAADAOF4z9QAAAACsR5EDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwexb5KrqA1X1QlV94hrPV1X9RlXtVNWTVfWWzY8JAPMjIwGYyipX5D6Y5OwXef7OJKeXfy4k+a0bHwsAhvDByEgAJrBvkevux5L86xdZcj7J7/fC40m+qqq+blMDAsBcyUgAprKJe+RuSfLcruMry3MAcNTJSAAOxLHDfLGqupDFW0vy2te+9lvf+MY3HubLAzCRj33sY//S3SemnmPOZCTA0XMj+biJIvd8klO7jk8uz/0f3X0xycUk2dra6suXL2/g5QGYu6r6x6lnmIiMBOCabiQfN/HWyu0kP7T8ZK63Jnmpu/95A18XAEYnIwE4EPtekauqDyV5W5LjVXUlyS8k+ZIk6e73J7mU5K4kO0k+l+RHDmpYAJgTGQnAVPYtct19zz7Pd5If39hEADAIGQnAVDbx1koAAAAOkSIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABjMSkWuqs5W1TNVtVNV91/l+Vur6tGq+nhVPVlVd21+VACYF/kIwFT2LXJVdVOSB5PcmeRMknuq6syeZT+f5OHufnOSu5P85qYHBYA5kY8ATGmVK3J3JNnp7me7++UkDyU5v2dNJ/nK5ePXJ/mnzY0IALMkHwGYzLEV1tyS5Lldx1eSfNueNb+Y5M+q6ieSvDbJOzYyHQDMl3wEYDKb+rCTe5J8sLtPJrkryR9U1f/52lV1oaouV9XlF198cUMvDQCztVI+JjISgPWsUuSeT3Jq1/HJ5bnd7k3ycJJ0918n+bIkx/d+oe6+2N1b3b114sSJ65sYAOZhY/m4fF5GArCyVYrcE0lOV9XtVXVzFjdrb+9Z8+kkb0+SqvqmLILKjxMBeDWTjwBMZt8i192vJLkvySNJPpnFp289VVUPVNW55bL3JHl3Vf1tkg8leVd390ENDQBTk48ATGmVDztJd19KcmnPuffuevx0ku/Y7GgAMG/yEYCpbOrDTgAAADgkihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMJiVilxVna2qZ6pqp6ruv8aaH6yqp6vqqar6w82OCQDzIx8BmMqx/RZU1U1JHkzyPUmuJHmiqra7++lda04n+dkk39Hdn62qrz2ogQFgDuQjAFNa5YrcHUl2uvvZ7n45yUNJzu9Z8+4kD3b3Z5Oku1/Y7JgAMDvyEYDJrFLkbkny3K7jK8tzu70hyRuq6q+q6vGqOrupAQFgpuQjAJPZ962Va3yd00neluRkkseq6pu7+992L6qqC0kuJMmtt966oZcGgNlaKR8TGQnAela5Ivd8klO7jk8uz+12Jcl2d/97d/9Dkr/LIrj+l+6+2N1b3b114sSJ650ZAOZgY/mYyEgA1rNKkXsiyemqur2qbk5yd5LtPWv+OIufNqaqjmfxVpJnNzcmAMyOfARgMvsWue5+Jcl9SR5J8skkD3f3U1X1QFWdWy57JMlnqurpJI8m+Znu/sxBDQ0AU5OPAEypunuSF97a2urLly9P8toAHK6q+lh3b009xyhkJMDRcCP5uNIvBAcAAGA+FDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDArFbmqOltVz1TVTlXd/0XWfV9VdVVtbW5EAJgn+QjAVPYtclV1U5IHk9yZ5EySe6rqzFXWvS7JTyb56KaHBIC5kY8ATGmVK3J3JNnp7me7++UkDyU5f5V1v5TkfUk+v8H5AGCu5CMAk1mlyN2S5Lldx1eW5/5bVb0lyanu/pMNzgYAcyYfAZjMDX/YSVW9JsmvJXnPCmsvVNXlqrr84osv3uhLA8BsrZOPy/UyEoCVrVLknk9yatfxyeW5//K6JG9K8pdV9akkb02yfbUburv7YndvdffWiRMnrn9qAJjexvIxkZEArGeVIvdEktNVdXtV3Zzk7iTb//Vkd7/U3ce7+7buvi3J40nOdfflA5kYAOZBPgIwmX2LXHe/kuS+JI8k+WSSh7v7qap6oKrOHfSAADBH8hGAKR1bZVF3X0pyac+5915j7dtufCwAmD/5CMBUbvjDTgAAADhcihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDArFbmqOltVz1TVTlXdf5Xnf7qqnq6qJ6vqz6vq6zc/KgDMi3wEYCr7FrmquinJg0nuTHImyT1VdWbPso8n2erub0nykSS/vOlBAWBO5CMAU1rlitwdSXa6+9nufjnJQ0nO717Q3Y929+eWh48nObnZMQFgduQjAJNZpcjdkuS5XcdXlueu5d4kf3ojQwHAAOQjAJM5tskvVlXvTLKV5Luu8fyFJBeS5NZbb93kSwPAbO2Xj8s1MhKAla1yRe75JKd2HZ9cnvtfquodSX4uybnu/sLVvlB3X+zure7eOnHixPXMCwBzsbF8TGQkAOtZpcg9keR0Vd1eVTcnuTvJ9u4FVfXmJL+dRUi9sPkxAWB25CMAk9m3yHX3K0nuS/JIkk8mebi7n6qqB6rq3HLZryT5iiR/VFV/U1Xb1/hyAPCqIB8BmNJK98h196Ukl/ace++ux+/Y8FwAMHvyEYCprPQLwQEAAJgPRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGMxKRa6qzlbVM1W1U1X3X+X5L62qDy+f/2hV3bbxSQFgZuQjAFPZt8hV1U1JHkxyZ5IzSe6pqjN7lt2b5LPd/f+S/HqS9216UACYE/kIwJRWuSJ3R5Kd7n62u19O8lCS83vWnE/ye8vHH0ny9qqqzY0JALMjHwGYzCpF7pYkz+06vrI8d9U13f1KkpeSfM0mBgSAmZKPAEzm2GG+WFVdSHJhefiFqvrEYb7+4I4n+ZephxiI/VqP/VqP/VrfN049wNzJyBvi7+R67Nd67Nd67Nd6rjsfVylyzyc5tev45PLc1dZcqapjSV6f5DN7v1B3X0xyMUmq6nJ3b13P0EeR/VqP/VqP/VqP/VpfVV2eeoYDsLF8TGTkjbBf67Ff67Ff67Ff67mRfFzlrZVPJDldVbdX1c1J7k6yvWfNdpIfXj7+/iR/0d19vUMBwADkIwCT2feKXHe/UlX3JXkkyU1JPtDdT1XVA0kud/d2kt9N8gdVtZPkX7MIMwB41ZKPAExppXvkuvtSkkt7zr131+PPJ/mBNV/74prrjzr7tR77tR77tR77tb5X5Z4dUD4mr9L9OkD2az32az32az32az3XvV/lHR4AAABjWeUeOQAAAGbkwItcVZ2tqmeqaqeq7r/K819aVR9ePv/RqrrtoGeasxX266er6umqerKq/ryqvn6KOediv/3ate77qqqr6kh/itIq+1VVP7j8Hnuqqv7wsGeckxX+Pt5aVY9W1ceXfyfvmmLOuaiqD1TVC9f62Pxa+I3lfj5ZVW857BnnRD6uRz6uT0auR0auR0au7sDysbsP7E8WN3//fZJvSHJzkr9NcmbPmh9L8v7l47uTfPggZ5rznxX367uTfPny8Y/ary++X8t1r0vyWJLHk2xNPfec9yvJ6SQfT/LVy+OvnXrume/XxSQ/unx8Jsmnpp574j37ziRvSfKJazx/V5I/TVJJ3prko1PPPOFeycfN75d8XHPPlutk5Ir7JSPX3i8Z+T97cSD5eNBX5O5IstPdz3b3y0keSnJ+z5rzSX5v+fgjSd5eVXXAc83VvvvV3Y929+eWh49n8XuLjqpVvr+S5JeSvC/J5w9zuBlaZb/eneTB7v5sknT3C4c845yssl+d5CuXj1+f5J8Ocb7Z6e7Hsvhkxms5n+T3e+HxJF9VVV93ONPNjnxcj3xcn4xcj4xcj4xcw0Hl40EXuVuSPLfr+Mry3FXXdPcrSV5K8jUHPNdcrbJfu92bRXs/qvbdr+Wl6VPd/SeHOdhMrfL99YYkb6iqv6qqx6vq7KFNNz+r7NcvJnlnVV3J4pMLf+JwRhvWuv/GvZrJx/XIx/XJyPXIyPXIyM26rnxc6dcPMD9V9c4kW0m+a+pZ5qqqXpPk15K8a+JRRnIsi7eOvC2Ln2Y/VlXf3N3/NuVQM3ZPkg92969W1bdn8fvC3tTd/zn1YHBUycfVyMjrIiPXIyMP2EFfkXs+yaldxyeX5666pqqOZXHp9TMHPNdcrbJfqap3JPm5JOe6+wuHNNsc7bdfr0vypiR/WVWfyuI9x9tH+GbuVb6/riTZ7u5/7+5/SPJ3WYTWUbTKft2b5OEk6e6/TvJlSY4fynRjWunfuCNCPq5HPq5PRq5HRq5HRm7WdeXjQRe5J5Kcrqrbq+rmLG7W3t6zZjvJDy8ff3+Sv+jlXX9H0L77VVVvTvLbWYTUUX5vdrLPfnX3S919vLtv6+7bsrhn4lx3X55m3Mmt8vfxj7P4SWOq6ngWbyN59hBnnJNV9uvTSd6eJFX1TVmE1IuHOuVYtpP80PLTud6a5KXu/ueph5qIfFyPfFyfjFyPjFyPjNys68rHA31rZXe/UlX3JXkki0+3+UB3P1VVDyS53N3bSX43i0utO1ncBHj3Qc40Zyvu168k+Yokf7S85/3T3X1usqEntOJ+sbTifj2S5Hur6ukk/5HkZ7r7SF4BWHG/3pPkd6rqp7K4qftdR/g/2qmqD2Xxn5zjy3sifiHJlyRJd78/i3sk7kqyk+RzSX5kmkmnJx/XIx/XJyPXIyPXIyPXc1D5WEd0PwEAAIZ14L8QHAAAgM1S5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAw+xa5qvpAVb1QVZ+4xvNVVb9RVTtV9WRVvWXzYwLA/MhIAKayyhW5DyY5+0WevzPJ6eWfC0l+68bHAoAhfDAyEoAJ7FvkuvuxJP/6RZacT/L7vfB4kq+qqq/b1IAAMFcyEoCpbOIeuVuSPLfr+MryHAAcdTISgANx7DBfrKouZPHWkrz2ta/91je+8Y2H+fIATORjH/vYv3T3iannmDMZCXD03Eg+bqLIPZ/k1K7jk8tz/0d3X0xyMUm2trb68uXLG3h5AOauqv5x6hkmIiMBuKYbycdNvLVyO8kPLT+Z661JXuruf97A1wWA0clIAA7EvlfkqupDSd6W5HhVXUnyC0m+JEm6+/1JLiW5K8lOks8l+ZGDGhYA5kRGAjCVfYtcd9+zz/Od5Mc3NhEADEJGAjCVTby1EgAAgEOkyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1mpyFXV2ap6pqp2qur+qzx/a1U9WlUfr6onq+quzY8KAPMiHwGYyr5FrqpuSvJgkjuTnElyT1Wd2bPs55M83N1vTnJ3kt/c9KAAMCfyEYAprXJF7o4kO939bHe/nOShJOf3rOkkX7l8/Pok/7S5EQFgluQjAJM5tsKaW5I8t+v4SpJv27PmF5P8WVX9RJLXJnnHRqYDgPmSjwBMZlMfdnJPkg9298kkdyX5g6r6P1+7qi5U1eWquvziiy9u6KUBYLZWysdERgKwnlWK3PNJTu06Prk8t9u9SR5Oku7+6yRfluT43i/U3Re7e6u7t06cOHF9EwPAPGwsH5fPy0gAVrZKkXsiyemqur2qbs7iZu3tPWs+neTtSVJV35RFUPlxIgCvZvIRgMnsW+S6+5Uk9yV5JMkns/j0raeq6oGqOrdc9p4k766qv03yoSTv6u4+qKEBYGryEYAprfJhJ+nuS0ku7Tn33l2Pn07yHZsdDQDmTT4CMJVNfdgJAAAAh0SRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMZqUiV1Vnq+qZqtqpqvuvseYHq+rpqnqqqv5ws2MCwPzIRwCmcmy/BVV1U5IHk3xPkitJnqiq7e5+etea00l+Nsl3dPdnq+prD2pgAJgD+QjAlFa5IndHkp3ufra7X07yUJLze9a8O8mD3f3ZJOnuFzY7JgDMjnwEYDKrFLlbkjy36/jK8txub0jyhqr6q6p6vKrObmpAAJgp+QjAZPZ9a+UaX+d0krclOZnksar65u7+t92LqupCkgtJcuutt27opQFgtlbKx0RGArCeVa7IPZ/k1K7jk8tzu11Jst3d/97d/5Dk77IIrv+luy9291Z3b504ceJ6ZwaAOdhYPiYyEoD1rFLknkhyuqpur6qbk9ydZHvPmj/O4qeNqarjWbyV5NnNjQkAsyMfAZjMvkWuu19Jcl+SR5J8MsnD3f1UVT1QVeeWyx5J8pmqejrJo0l+prs/c1BDA8DU5CMAU6runuSFt7a2+vLly5O8NgCHq6o+1t1bU88xChkJcDTcSD6u9AvBAQAAmA9FDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYzEpFrqrOVtUzVbVTVfd/kXXfV1VdVVubGxEA5kk+AjCVfYtcVd2U5MEkdyY5k+SeqjpzlXWvS/KTST666SEBYG7kIwBTWuWK3B1Jdrr72e5+OclDSc5fZd0vJXlfks9vcD4AmCv5CMBkVilytyR5btfxleW5/1ZVb0lyqrv/ZIOzAcCcyUcAJnPDH3ZSVa9J8mtJ3rPC2gtVdbmqLr/44os3+tIAMFvr5ONyvYwEYGWrFLnnk5zadXxyee6/vC7Jm5L8ZVV9Kslbk2xf7Ybu7r7Y3VvdvXXixInrnxoAprexfExkJADrWaXIPZHkdFXdXlU3J7k7yfZ/PdndL3X38e6+rbtvS/J4knPdfflAJgaAeZCPAExm3yLX3a8kuS/JI0k+meTh7n6qqh6oqnMHPSAAzJF8BGBKx1ZZ1N2Xklzac+6911j7thsfCwDmTz4CMJUb/rATAAAADpciBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMZqUiV1Vnq+qZqtqpqvuv8vxPV9XTVfVkVf15VX395kcFgHmRjwBMZd8iV1U3JXkwyZ1JziS5p6rO7Fn28SRb3f0tST6S5Jc3PSgAzIl8BGBKq1yRuyPJTnc/290vJ3koyfndC7r70e7+3PLw8SQnNzsmAMyOfARgMqsUuVuSPLfr+Mry3LXcm+RPb2QoABiAfARgMsc2+cWq6p1JtpJ81zWev5DkQpLceuutm3xpAJit/fJxuUZGArCyVa7IPZ/k1K7jk8tz/0tVvSPJzyU5191fuNoX6u6L3b3V3VsnTpy4nnkBYC42lo+JjARgPasUuSeSnK6q26vq5iR3J9nevaCq3pzkt7MIqRc2PyYAzI58BGAy+xa57n4lyX1JHknyySQPd/dTVfVAVZ1bLvuVJF+R5I+q6m+qavsaXw4AXhXkIwBTWukeue6+lOTSnnPv3fX4HRueCwBmTz4CMJWVfiE4AAAA86HIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGs1KRq6qzVfVMVe1U1f1Xef5Lq+rDy+c/WlW3bXxSAJgZ+QjAVPYtclV1U5IHk9yZ5EySe6rqzJ5l9yb5bHf/vyS/nuR9mx4UAOZEPgIwpVWuyN2RZKe7n+3ul5M8lOT8njXnk/ze8vFHkry9qmpzYwLA7MhHACazSpG7Jclzu46vLM9ddU13v5LkpSRfs4kBAWCm5CMAkzl2mC9WVReSXFgefqGqPnGYrz+440n+ZeohBmK/1mO/1mO/1veNUw8wdzLyhvg7uR77tR77tR77tZ7rzsdVitzzSU7tOj65PHe1NVeq6liS1yf5zN4v1N0Xk1xMkqq63N1b1zP0UWS/1mO/1mO/1mO/1ldVl6ee4QBsLB8TGXkj7Nd67Nd67Nd67Nd6biQfV3lr5RNJTlfV7VV1c5K7k2zvWbOd5IeXj78/yV90d1/vUAAwAPkIwGT2vSLX3a9U1X1JHklyU5IPdPdTVfVAksvdvZ3kd5P8QVXtJPnXLMIMAF615CMAU1rpHrnuvpTk0p5z7931+PNJfmDN17645vqjzn6tx36tx36tx36t71W5ZweUj8mrdL8OkP1aj/1aj/1aj/1az3XvV3mHBwAAwFhWuUcOAACAGTnwIldVZ6vqmaraqar7r/L8l1bVh5fPf7SqbjvomeZshf366ap6uqqerKo/r6qvn2LOudhvv3at+76q6qo60p+itMp+VdUPLr/HnqqqPzzsGedkhb+Pt1bVo1X18eXfybummHMuquoDVfXCtT42vxZ+Y7mfT1bVWw57xjmRj+uRj+uTkeuRkeuRkas7sHzs7gP7k8XN33+f5BuS3Jzkb5Oc2bPmx5K8f/n47iQfPsiZ5vxnxf367iRfvnz8o/bri+/Xct3rkjyW5PEkW1PPPef9SnI6yceTfPXy+Gunnnvm+3UxyY8uH59J8qmp5554z74zyVuSfOIaz9+V5E+TVJK3Jvno1DNPuFfycfP7JR/X3LPlOhm54n7JyLX3S0b+z14cSD4e9BW5O5LsdPez3f1ykoeSnN+z5nyS31s+/kiSt1dVHfBcc7XvfnX3o939ueXh41n83qKjapXvryT5pSTvS/L5wxxuhlbZr3cnebC7P5sk3f3CIc84J6vsVyf5yuXj1yf5p0Ocb3a6+7EsPpnxWs4n+f1eeDzJV1XV1x3OdLMjH9cjH9cnI9cjI9cjI9dwUPl40EXuliTP7Tq+sjx31TXd/UqSl5J8zQHPNVer7Ndu92bR3o+qffdreWn6VHf/yWEONlOrfH+9Ickbquqvqurxqjp7aNPNzyr79YtJ3llVV7L45MKfOJzRhrXuv3GvZvJxPfJxfTJyPTJyPTJys64rH1f69QPMT1W9M8lWku+aepa5qqrXJPm1JO+aeJSRHMvirSNvy+Kn2Y9V1Td3979NOdSM3ZPkg939q1X17Vn8vrA3dfd/Tj0YHFXycTUy8rrIyPXIyAN20Ffknk9yatfxyeW5q66pqmNZXHr9zAHPNVer7Feq6h1Jfi7Jue7+wiHNNkf77dfrkrwpyV9W1aeyeM/x9hG+mXuV768rSba7+9+7+x+S/F0WoXUUrbJf9yZ5OEm6+6+TfFmS44cy3ZhW+jfuiJCP65GP65OR65GR65GRm3Vd+XjQRe6JJKer6vaqujmLm7W396zZTvLDy8ffn+QvennX3xG0735V1ZuT/HYWIXWU35ud7LNf3f1Sdx/v7tu6+7Ys7pk4192Xpxl3cqv8ffzjLH7SmKo6nsXbSJ49xBnnZJX9+nSStydJVX1TFiH14qFOOZbtJD+0/HSutyZ5qbv/eeqhJiIf1yMf1ycj1yMj1yMjN+u68vFA31rZ3a9U1X1JHsni020+0N1PVdUDSS5393aS383iUutOFjcB3n2QM83Zivv1K0m+IskfLe95/3R3n5ts6AmtuF8srbhfjyT53qp6Osl/JPmZ7j6SVwBW3K/3JPmdqvqpLG7qftcR/o92qupDWfwn5/jynohfSPIlSdLd78/iHom7kuwk+VySH5lm0unJx/XIx/XJyPXIyPXIyPUcVD7WEd1PAACAYR34LwQHAABgsxQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDD/H1ntSQfdPRK3AAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}